{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22586ba4-8664-410f-a87e-9a6e378bb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Standard library =====\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "# ===== Third-party =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.cm import Blues, Reds\n",
    "from matplotlib.colors import to_rgb\n",
    "\n",
    "\n",
    "# ----- File locations ---------------------------------------------------\n",
    "ROOT      = Path(\".\") / \"Experiment_004\"\n",
    "DIM_TXT   = ROOT / \"Dimensional_Data.txt\"\n",
    "TEN_TXT   = ROOT / \"Tensile_Data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0ecca6-ffc4-4db8-91d1-6b034f92ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba(mat_color, alpha: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Convert a Matplotlib colour (any valid *RGB tuple* or *hex string*)\n",
    "    to a Plotly-compatible 'rgba(r,g,b,a)' string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat_color : tuple | str\n",
    "        3-tuple of floats in 0-1 or any colour string accepted by\n",
    "        ``matplotlib.colors.to_rgb`` (e.g. '#2a9d8f').\n",
    "    alpha : float, default 1.0\n",
    "        Alpha channel 0–1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        CSS-style rgba(…) string.\n",
    "    \"\"\"\n",
    "    r, g, b = (np.array(to_rgb(mat_color)) * 255).astype(int)\n",
    "    return f\"rgba({r},{g},{b},{alpha})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e208014f-a141-4b34-b6ec-2470d9b5e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionalData:\n",
    "    \"\"\"\n",
    "    Parse a Dia-Stron dimensional *.txt* file and expose a\n",
    "    *slot → mean-area (µm²)* mapping.\n",
    "\n",
    "    Design goals\n",
    "    ------------\n",
    "    * Accept rows appended out of order (reruns).\n",
    "    * Silently skip blank / malformed rows.\n",
    "    * Avoid heavy deps (only NumPy / Pandas).\n",
    "    \"\"\"\n",
    "\n",
    "    _AREA_RE = re.compile(r\"cross.*area\", re.I)      # locate area column\n",
    "    _NUM_RE  = re.compile(r\"^\\d+(\\.\\d+)?$\")          # basic numeric check\n",
    "\n",
    "    def __init__(self, path: Path):\n",
    "        lines = path.read_text().splitlines()\n",
    "        hdr_idx = next(i for i, l in enumerate(lines) if l.startswith(\"Record\"))\n",
    "        header  = [c.strip() for c in lines[hdr_idx].split(\"\\t\")]\n",
    "\n",
    "        try:\n",
    "            area_idx = next(i for i, c in enumerate(header)\n",
    "                            if self._AREA_RE.search(c))\n",
    "        except StopIteration as exc:\n",
    "            raise ValueError(\"Area column not found\") from exc\n",
    "        print(f\"[DEBUG] Area column index = {area_idx}\")\n",
    "\n",
    "        slot_vals: dict[int, list[float]] = {}\n",
    "\n",
    "        for row in lines[hdr_idx + 1 :]:\n",
    "            if not row.strip():\n",
    "                continue\n",
    "            parts = row.split(\"\\t\")\n",
    "            if len(parts) <= area_idx:\n",
    "                continue\n",
    "\n",
    "            rec, area = parts[0].strip(), parts[area_idx].strip()\n",
    "            if not self._NUM_RE.match(area):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                slot = int(float(rec))\n",
    "                area_val = float(area)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            slot_vals.setdefault(slot, []).append(area_val)\n",
    "\n",
    "        if not slot_vals:\n",
    "            raise ValueError(\"No numeric area entries parsed\")\n",
    "\n",
    "        self.map: dict[int, float] = {\n",
    "            slot: float(np.mean(vals)) for slot, vals in slot_vals.items()\n",
    "        }\n",
    "        print(f\"[DEBUG] Dimensional – slots parsed: {len(self.map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e1b7cb-2664-4c20-aa14-380aee061fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Cell 4  ────────────────────────────────────────────────────────────\n",
    "class TensileTest:\n",
    "    \"\"\"\n",
    "    Wrapper for Dia-Stron tensile .txt files.\n",
    "\n",
    "    The file can contain either:\n",
    "      • raw gram-force   (column 'gmf')\n",
    "      • engineering MPa  (any header in MPa_HEADERS)\n",
    "\n",
    "    Provides\n",
    "    --------\n",
    "    self.df        – cleaned full DataFrame\n",
    "    per_slot()     – generator yielding (slot, df_slot)\n",
    "    stress_strain  – convert df_slot → with strain + stress_Pa columns\n",
    "    metrics()      – static helper for UTS, break values, Young’s modulus\n",
    "    \"\"\"\n",
    "\n",
    "    GF_TO_N     = 0.00981\n",
    "    MPa_HEADERS = {\"mpa\", \"stress\", \"stress_mpa\"}\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # construction                                                       #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def __init__(self, path: Path):\n",
    "        raw_lines = path.read_text().splitlines()\n",
    "\n",
    "        header: list[str] | None = None\n",
    "        body:   list[str] = []\n",
    "        for ln in raw_lines:\n",
    "            if ln.startswith(\"Record\"):\n",
    "                header = [c.strip() for c in ln.split(\"\\t\") if c.strip()]\n",
    "            elif header and ln.strip():\n",
    "                body.append(ln)\n",
    "\n",
    "        if header is None:  # pragma: no cover\n",
    "            raise ValueError(\"Header line starting with 'Record' not found\")\n",
    "\n",
    "        df = pd.read_csv(StringIO(\"\\n\".join(body)), sep=\"\\t\", names=header)\n",
    "\n",
    "        # ---- normalise columns --------------------------------------------\n",
    "        df.rename(columns=lambda c: c.strip(), inplace=True)\n",
    "        if \"% Strain\" in df.columns:\n",
    "            df.rename(columns={\"% Strain\": \"Strain_pct\"}, inplace=True)\n",
    "\n",
    "        # ---- detect stress units ------------------------------------------\n",
    "        col_lut  = {c.lower(): c for c in df.columns}\n",
    "        mpa_cols = [orig for low, orig in col_lut.items()\n",
    "                    if low in self.MPa_HEADERS]\n",
    "        self.is_mpa = bool(mpa_cols)\n",
    "        stress_col  = mpa_cols[0] if self.is_mpa else \"gmf\"\n",
    "        print(f\"[DEBUG] Tensile units: \"\n",
    "              f\"{'MPa' if self.is_mpa else 'gmf'} (column '{stress_col}')\")\n",
    "\n",
    "        # ---- clean numeric data -------------------------------------------\n",
    "        df.rename(columns={stress_col: \"raw_stress\"}, inplace=True)\n",
    "        df[\"Record\"]     = pd.to_numeric(df[\"Record\"],     errors=\"coerce\")\n",
    "        df[\"Strain_pct\"] = pd.to_numeric(df[\"Strain_pct\"], errors=\"coerce\")\n",
    "        df[\"raw_stress\"] = pd.to_numeric(df[\"raw_stress\"], errors=\"coerce\")\n",
    "\n",
    "        self.df = (\n",
    "            df.dropna(subset=[\"Record\", \"Strain_pct\", \"raw_stress\"])\n",
    "              .astype({\"Record\": int})\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # public helpers                                                     #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def per_slot(self):\n",
    "        \"\"\"Yield (slot_number, DataFrame) pairs in ascending slot order.\"\"\"\n",
    "        for slot, grp in self.df.groupby(\"Record\", sort=True):\n",
    "            yield slot, grp.reset_index(drop=True)\n",
    "\n",
    "    def stress_strain(self, df_slot: pd.DataFrame, area_um2: float) -> pd.DataFrame:\n",
    "        \"\"\"Convert raw slot data → engineering strain + true stress (Pa).\"\"\"\n",
    "        out = df_slot.copy()\n",
    "        out[\"strain\"] = out[\"Strain_pct\"] / 100\n",
    "        if self.is_mpa:\n",
    "            out[\"stress_Pa\"] = out[\"raw_stress\"] * 1_000_000\n",
    "        else:\n",
    "            out[\"stress_Pa\"] = (\n",
    "                out[\"raw_stress\"] * self.GF_TO_N / (area_um2 * 1e-12)\n",
    "            )\n",
    "        return out\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # static metrics                                                     #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    @staticmethod\n",
    "    def metrics(df: pd.DataFrame) -> tuple[float, float, float, float]:\n",
    "        \"\"\"Return UTS, break stress, break strain, Young’s modulus.\"\"\"\n",
    "        s = df[\"stress_Pa\"].to_numpy()\n",
    "        e = df[\"strain\"].to_numpy()\n",
    "\n",
    "        idx = s.argmax()\n",
    "        uts          = s[idx]              # Pa\n",
    "        brk_stress   = s[idx]              # Pa (same as UTS in this file format)\n",
    "        brk_strain   = e[idx] * 100        # %\n",
    "        linear_mask  = e <= 0.002\n",
    "        E = (\n",
    "            np.polyfit(e[linear_mask], s[linear_mask], 1)[0]\n",
    "            if linear_mask.sum() > 1 else np.nan\n",
    "        )\n",
    "        return uts / 1e6, brk_stress / 1e6, brk_strain, E / 1e9\n",
    "\n",
    "    @staticmethod\n",
    "    def yield_gradient(df: pd.DataFrame,\n",
    "                       low_pct: float = 7.0,\n",
    "                       high_pct: float = 16.0) -> float:\n",
    "        \"\"\"\n",
    "        Slope (MPa / % strain) between `low_pct` and `high_pct` strain.\n",
    "        \"\"\"\n",
    "        if high_pct <= low_pct:\n",
    "            raise ValueError(\"high_pct must be greater than low_pct\")\n",
    "\n",
    "        e_pct = df[\"strain\"].to_numpy() * 100\n",
    "        s_pa  = df[\"stress_Pa\"].to_numpy()\n",
    "        if e_pct.size < 2:\n",
    "            return np.nan\n",
    "        # ensure ascending order before interpolation\n",
    "        idx   = np.argsort(e_pct)\n",
    "        e_pct = e_pct[idx]\n",
    "        s_pa  = s_pa[idx]\n",
    "\n",
    "        if e_pct.min() > low_pct or e_pct.max() < high_pct:\n",
    "            return np.nan\n",
    "\n",
    "        σ_low  = np.interp(low_pct,  e_pct, s_pa)\n",
    "        σ_high = np.interp(high_pct, e_pct, s_pa)\n",
    "\n",
    "        return ((σ_high - σ_low) / 1e6) / (high_pct - low_pct)\n",
    "\n",
    "# ---- helper: post-gradient slope (MPa per % strain) -------------------\n",
    "def post_gradient(proc_df: pd.DataFrame, delta_pct: float = 8.0) -> float:\n",
    "    \"\"\"\n",
    "    Return slope MPa / % between break point and (break − Δε) point.\n",
    "    \"\"\"\n",
    "    s = proc_df[\"stress_Pa\"].to_numpy()\n",
    "    e = proc_df[\"strain\"].to_numpy()          # 0–1\n",
    "    if len(s) < 3:\n",
    "        return np.nan\n",
    "    idx_break = s.argmax()\n",
    "    brk_strain_pct = e[idx_break] * 100\n",
    "    target_pct = brk_strain_pct - delta_pct\n",
    "    if target_pct < 0:\n",
    "        return np.nan\n",
    "\n",
    "    anchor_idx = np.where(e * 100 <= target_pct)[0]\n",
    "    if anchor_idx.size == 0:\n",
    "        return np.nan\n",
    "    anchor_idx = anchor_idx[-1]\n",
    "\n",
    "    dσ_MPa = (s[idx_break] - s[anchor_idx]) / 1e6\n",
    "    dε_pct = brk_strain_pct - e[anchor_idx] * 100\n",
    "    return dσ_MPa / dε_pct if dε_pct else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d6f357-25be-46fa-9536-d3e45dd4b88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Experiment_004\\\\Dimensional_Data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m areas \u001b[38;5;241m=\u001b[39m DimensionalData(DIM_TXT)\u001b[38;5;241m.\u001b[39mmap\n\u001b[0;32m      3\u001b[0m raw   \u001b[38;5;241m=\u001b[39m TensileTest(TEN_TXT)         \u001b[38;5;66;03m# the class that now includes yield_gradient()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m blues, reds \u001b[38;5;241m=\u001b[39m Blues(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m50\u001b[39m)), Reds(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m50\u001b[39m))\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mDimensionalData.__init__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: Path):\n\u001b[1;32m---> 17\u001b[0m     lines \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mread_text()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m     18\u001b[0m     hdr_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines) \u001b[38;5;28;01mif\u001b[39;00m l\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecord\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     19\u001b[0m     header  \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lines[hdr_idx]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\pathlib.py:1027\u001b[0m, in \u001b[0;36mPath.read_text\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;124;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1027\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1012\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Experiment_004\\\\Dimensional_Data.txt'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "areas = DimensionalData(DIM_TXT).map\n",
    "raw   = TensileTest(TEN_TXT)         # the class that now includes yield_gradient()\n",
    "\n",
    "blues, reds = Blues(np.linspace(0.4, 0.9, 50)), Reds(np.linspace(0.4, 0.9, 50))\n",
    "fig_overlay = go.Figure()\n",
    "\n",
    "metric_rows, curve_rows = [], []\n",
    "miss_area, empty_slot   = [], []\n",
    "slots_plotted           = []\n",
    "\n",
    "for slot, df_raw in raw.per_slot():\n",
    "    if slot not in areas:\n",
    "        miss_area.append(slot)\n",
    "        continue\n",
    "\n",
    "    proc = raw.stress_strain(df_raw, areas[slot])\n",
    "    if proc.empty:\n",
    "        empty_slot.append(slot)\n",
    "        continue\n",
    "\n",
    "    slots_plotted.append(slot)\n",
    "    cond = \"1-50\" if slot <= 50 else \"51-100\"\n",
    "\n",
    "    # --- store every curve point (for optional export / separate visual) ---\n",
    "    curve_rows += [\n",
    "        {\"Slot\": slot, \"Condition\": cond,\n",
    "         \"Strain\": st, \"Stress_MPa\": sp / 1e6}\n",
    "        for st, sp in zip(proc[\"strain\"], proc[\"stress_Pa\"])\n",
    "    ]\n",
    "\n",
    "    # --- overlay plot -------------------------------------------------------\n",
    "    col = (rgba(blues[slot - 1]) if 1 <= slot <= 50\n",
    "           else rgba(reds[slot - 51]) if 51 <= slot <= 100\n",
    "           else \"grey\")\n",
    "    fig_overlay.add_trace(go.Scattergl(\n",
    "        x=proc[\"strain\"], y=proc[\"stress_Pa\"] / 1e6,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=col, width=1),\n",
    "        name=f\"Slot {slot}\",\n",
    "        hovertemplate=f\"Slot {slot}<br>Strain=%{{x:.3f}}<br>Stress=%{{y:.2f}} MPa\"\n",
    "    ))\n",
    "\n",
    "    # --- per-slot metrics ---------------------------------------------------\n",
    "    uts, bs, bp, E = TensileTest.metrics(proc)         \n",
    "    grad_post = post_gradient(proc, delta_pct=8.0)     \n",
    "    grad_yld  = TensileTest.yield_gradient(proc)      \n",
    "\n",
    "    metric_rows.append({\n",
    "        \"Slot\": slot,\n",
    "        \"Condition\": cond,\n",
    "        \"UTS_MPa\": uts,\n",
    "        \"Break_Stress_MPa\": bs,\n",
    "        \"Break_Strain_%\": bp,\n",
    "        \"Youngs_Modulus_GPa\": E,\n",
    "        \"Post_Gradient_MPa_perc\": grad_post,\n",
    "        \"Yield_Gradient_MPa_perc\": grad_yld,           \n",
    "    })\n",
    "\n",
    "# ---- tidy DataFrames ---------------------------------------------------\n",
    "summary_df = pd.DataFrame(metric_rows).set_index(\"Slot\")\n",
    "curves_df  = pd.DataFrame(curve_rows)\n",
    "\n",
    "# ── Overlay buttons (use real slots) -----------------------------------\n",
    "N       = len(fig_overlay.data)\n",
    "vis_all = [True] * N\n",
    "vis1    = [s <= 50 for s in slots_plotted]\n",
    "vis2    = [s >= 51 for s in slots_plotted]\n",
    "\n",
    "fig_overlay.update_layout(\n",
    "    title=\"Experiment 002 – stress–strain curves\",\n",
    "    xaxis_title=\"Strain\",\n",
    "    yaxis_title=\"Stress (MPa)\",\n",
    "    template=\"simple_white\",\n",
    "    height=750,\n",
    "    legend=dict(title=\"Toggle curves\",\n",
    "                y=1, x=1.02, orientation=\"v\", borderwidth=1),\n",
    "    updatemenus=[dict(\n",
    "        type=\"buttons\",\n",
    "        direction=\"right\",\n",
    "        x=0.02, y=1.08, showactive=True,\n",
    "        buttons=[\n",
    "            dict(label=\"Show All\",    method=\"update\",\n",
    "                 args=[{\"visible\": vis_all}]),\n",
    "            dict(label=\"Slots 1–50\",  method=\"update\",\n",
    "                 args=[{\"visible\": vis1}]),\n",
    "            dict(label=\"Slots 51–100\", method=\"update\",\n",
    "                 args=[{\"visible\": vis2}]),\n",
    "        ])\n",
    "    ])\n",
    "fig_overlay.show()\n",
    "\n",
    "# ── Cat-plots + Welch-t summary table ──────────────────────────────────\n",
    "metrics = [\"UTS_MPa\", \"Break_Stress_MPa\", \"Break_Strain_%\",\n",
    "           \"Youngs_Modulus_GPa\", \"Post_Gradient_MPa_perc\",\n",
    "           \"Yield_Gradient_MPa_perc\"]                       # ← NEW metric added\n",
    "titles  = [\"UTS (MPa)\", \"Break Stress (MPa)\",\n",
    "           \"Break Strain (%)\", \"Young’s Modulus (GPa)\",\n",
    "           \"Post-gradient (MPa / % strain)\",\n",
    "           \"Yield gradient (MPa / % strain)\"]              # ← NEW title\n",
    "colors  = {\"1-50\": rgba(blues[-1]), \"51-100\": rgba(reds[-1])}\n",
    "\n",
    "# 6 metrics → 3 rows × 2 cols; add an extra row for the table\n",
    "cat = make_subplots(\n",
    "    rows=4, cols=2,\n",
    "    subplot_titles=titles + [\"Welch t-tests\"],\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.14,\n",
    "    specs=[\n",
    "        [{}, {}],\n",
    "        [{}, {}],\n",
    "        [{}, {}],\n",
    "        [ {}, {\"type\": \"table\"}],      # row 4: left blank, table on the right\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---- add box-plots -----------------------------------------------------\n",
    "for i, m in enumerate(metrics):\n",
    "    r, c = divmod(i, 2)           # 0-indexed\n",
    "    r += 1; c += 1                # make_subplots is 1-indexed\n",
    "    for cond in [\"1-50\", \"51-100\"]:\n",
    "        cat.add_trace(go.Box(\n",
    "            y=summary_df[summary_df[\"Condition\"] == cond][m],\n",
    "            name=cond,\n",
    "            marker_color=colors[cond],\n",
    "            boxmean=\"sd\",\n",
    "            boxpoints=\"all\",\n",
    "            jitter=0.35,\n",
    "            pointpos=0,\n",
    "            showlegend=(i == 0)),               # only show legend once\n",
    "            row=r, col=c\n",
    "        )\n",
    "    cat.update_yaxes(title_text=titles[i], row=r, col=c)\n",
    "    cat.update_xaxes(showticklabels=False, row=r, col=c)\n",
    "\n",
    "# ---- Welch-t + effect size table --------------------------------------\n",
    "def cohen_d(a, b):\n",
    "    \"\"\"Unbiased pooled Cohen’s d.\"\"\"\n",
    "    n1, n2 = len(a), len(b)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return np.nan\n",
    "    s1, s2 = a.std(ddof=1), b.std(ddof=1)\n",
    "    pooled = math.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
    "    return (a.mean() - b.mean()) / pooled if pooled else np.nan\n",
    "\n",
    "rows_tbl = []\n",
    "for m in metrics:\n",
    "    g1 = summary_df[summary_df[\"Condition\"] == \"1-50\"][m].dropna()\n",
    "    g2 = summary_df[summary_df[\"Condition\"] == \"51-100\"][m].dropna()\n",
    "    if len(g1) and len(g2):\n",
    "        t, p = ttest_ind(g1, g2, equal_var=False)\n",
    "        d    = abs(cohen_d(g1, g2))\n",
    "        sig  = \"Yes\" if p < 0.05 else \"No\"\n",
    "        if   d >= 0.8:  eff = \"Large\"\n",
    "        elif d >= 0.5:  eff = \"Medium\"\n",
    "        elif d >= 0.2:  eff = \"Small\"\n",
    "        else:           eff = \"Negligible\"\n",
    "    else:\n",
    "        t, p, d, sig, eff = (np.nan, np.nan, np.nan, \"N/A\", \"N/A\")\n",
    "\n",
    "    rows_tbl.append([\n",
    "        titles[metrics.index(m)], f\"{t:6.2f}\", f\"{p:.3g}\",\n",
    "        f\"{d:.2f}\", sig, eff\n",
    "    ])\n",
    "\n",
    "header = [\"Metric\", \"t\", \"p-value\", \"|d|\", \"p < 0.05?\", \"Effect\"]\n",
    "cat.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(values=header, fill_color=\"#f2f2f2\", align=\"center\"),\n",
    "        cells=dict(values=list(map(list, zip(*rows_tbl))), align=\"center\")\n",
    "    ),\n",
    "    row=4, col=2\n",
    ")\n",
    "\n",
    "cat.update_layout(\n",
    "    height=1300, width=1050,\n",
    "    template=\"simple_white\",\n",
    "    title=\"Experiment 002 – metric distributions + Welch t-tests\",\n",
    "    boxmode=\"group\"\n",
    ")\n",
    "cat.show()\n",
    "\n",
    "# ── Export both metrics & stats ────────────────────────────────────────\n",
    "summary_df.to_excel(ROOT / f\"{ROOT.name}_metrics.xlsx\", sheet_name=\"Metrics\")\n",
    "pd.DataFrame(rows_tbl, columns=header).to_excel(\n",
    "    ROOT / f\"{ROOT.name}_stats.xlsx\", index=False)\n",
    "\n",
    "print(\"[INFO] Metrics exported →\", ROOT / f\"{ROOT.name}_metrics.xlsx\")\n",
    "print(\"[INFO] Stats   exported →\", ROOT / f\"{ROOT.name}_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70a877-0a92-494f-8354-905534a03839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
